{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JBLeeDeepLearn_First_NeuralNet_WithKeras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO5A0dqA1h5awR/L+vqeqWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athiagarajan/JBLeeFiles/blob/master/JBLeeDeepLearn_First_NeuralNet_WithKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtmMhqfsL9Bw",
        "colab_type": "text"
      },
      "source": [
        "# **First Neural Network With Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XwKafVMDeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "model.add(Dense(8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "model.add(Dense(1, kernel_initializer='uniform' , activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "# Fit the model\n",
        "model.fit(X, Y, nb_epoch=150, batch_size=10)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOht0CaHPl3U",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluating Performance of Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o65_qHYVPtXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "model.add(Dense(8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "model.add(Dense(1, kernel_initializer='uniform' , activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10)\n",
        "# evaluate the model\n",
        "#scores = model.evaluate(X, Y)\n",
        "#print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxQiK9OAQR-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP with manual validation set\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# split into 67% for train and 33% for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "model.add(Dense(8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "model.add(Dense(1, kernel_initializer='uniform' , activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcWMVmtsRI5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, Y):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "  model.add(Dense(8, kernel_initializer='uniform' , activation= 'relu' ))\n",
        "  model.add(Dense(1, kernel_initializer='uniform' , activation= 'sigmoid' ))\n",
        "  # Compile model\n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "  # Fit the model\n",
        "  model.fit(X[train], Y[train], nb_epoch=150, batch_size=10, verbose=0)\n",
        "  # evaluate the model\n",
        "  scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO8xI3dIbLDS",
        "colab_type": "text"
      },
      "source": [
        "#**Keras Models With Scikit-Learn For General Machine Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_3B4YJCb3bS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26170aa8-b438-48cd-b38d-433c90bd3976"
      },
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, kernel_initializer= 'uniform' , activation= 'relu' ))\n",
        "  model.add(Dense(8, kernel_initializer= 'uniform' , activation= 'relu' ))\n",
        "  model.add(Dense(1, kernel_initializer= 'uniform' , activation= 'sigmoid' ))\n",
        "  # Compile model\n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "  return model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=0)\n",
        "# evaluate using 10-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6510594606399536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtrUea2QNx9M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5fed98fe-8eec-4f8b-da8f-43f9976280f4"
      },
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "init = [ 'glorot_uniform' , 'normal' , 'uniform' ]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.701823 using {'batch_size': 20, 'epochs': 100}\n",
            "0.647135 (0.009207) with: {'batch_size': 10, 'epochs': 10}\n",
            "0.674479 (0.033197) with: {'batch_size': 10, 'epochs': 50}\n",
            "0.699219 (0.003189) with: {'batch_size': 10, 'epochs': 100}\n",
            "0.628906 (0.046329) with: {'batch_size': 20, 'epochs': 10}\n",
            "0.652344 (0.022326) with: {'batch_size': 20, 'epochs': 50}\n",
            "0.701823 (0.032264) with: {'batch_size': 20, 'epochs': 100}\n",
            "0.533854 (0.028587) with: {'batch_size': 40, 'epochs': 10}\n",
            "0.652344 (0.013902) with: {'batch_size': 40, 'epochs': 50}\n",
            "0.660156 (0.035943) with: {'batch_size': 40, 'epochs': 100}\n",
            "0.536458 (0.080771) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.606771 (0.043537) with: {'batch_size': 60, 'epochs': 50}\n",
            "0.658854 (0.040637) with: {'batch_size': 60, 'epochs': 100}\n",
            "0.576823 (0.092237) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.640625 (0.022326) with: {'batch_size': 80, 'epochs': 50}\n",
            "0.669271 (0.015733) with: {'batch_size': 80, 'epochs': 100}\n",
            "0.497396 (0.070769) with: {'batch_size': 100, 'epochs': 10}\n",
            "0.608073 (0.015073) with: {'batch_size': 100, 'epochs': 50}\n",
            "0.677083 (0.016367) with: {'batch_size': 100, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}