{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_SentimentAnalysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrWvwG70kWol3QPR4mGaES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athiagarajan/JBLeeFiles/blob/master/DeepLearning_SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7-Q8Leu79Q3"
      },
      "source": [
        "https://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu9AhQw2702l"
      },
      "source": [
        "#https://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/\r\n",
        "# MLP for the IMDB problem\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.preprocessing import sequence\r\n",
        "# load the dataset but only keep the top n words, zero the rest\r\n",
        "top_words = 5000\r\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\r\n",
        "max_words = 500\r\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\r\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\r\n",
        "# create the model\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(250, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "# Fit the model\r\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\r\n",
        "# Final evaluation of the model\r\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvV8dbHx8X5_"
      },
      "source": [
        "# CNN for the IMDB problem\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers.convolutional import Conv1D\r\n",
        "from keras.layers.convolutional import MaxPooling1D\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.preprocessing import sequence\r\n",
        "# load the dataset but only keep the top n words, zero the rest\r\n",
        "top_words = 5000\r\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\r\n",
        "# pad dataset to a maximum review length in words\r\n",
        "max_words = 500\r\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\r\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\r\n",
        "# create the model\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\r\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\r\n",
        "model.add(MaxPooling1D())\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(250, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "# Fit the model\r\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\r\n",
        "# Final evaluation of the model\r\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}